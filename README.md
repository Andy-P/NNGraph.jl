# NNGraph.jl

NNGraph.jl is a Julia language package with functionality to construct arbitrary **expression graphs** over which the library can perform **automatic differentiation** similar to what you may find in Theano for Python, or in Torch etc. It is useful for creating arbitrary neural networks and was developed with a focus on enabling fast experimentation.

## Example code

The core of the library is a **Graph** structure which maintains the links between matrices and how they are related th Here is how you would implement a simple Neural Network layer:

```julia
# T.B.D.
Will added soon ... I hope :)
```

To construct and train an LSTM for example, you would proceed as follows:

```julia
# T.B.D.
Will added soon ...
```
## Credits
NNGraph.jl is based on a portion Andrej Karpathy's excellent [RecurrentJS](http://cs.stanford.edu/people/karpathy/recurrentjs) library in javascript.  Speed enhancements were added by [Iain Dunning](https://github.com/IainNZ). Some of [Paul Heideman](https://github.com/paulheideman) work on RecurrentNN.jl graph function have been used here.

## License
MIT
